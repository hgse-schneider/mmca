digraph world {
        size="15,15";
        layout=neato
        graph [fontname = "helvetica"];
        node [fontname = "helvetica", colorscheme=set28];
        edge [fontname = "helvetica", colorscheme=set28];

	"communication" [href="index.svg"];
	"Facial expression" [href="https://scholar.google.com/scholar?hl=en&q=Going%20beyond%20what%20is%20visible:%20What%20multichannel%20data%20can%20reveal%20about%20interaction%20in%20the%20context%20of%20collaborative%20learning?" target="_blank" , color="6"];
	"Signal Matching (SM" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="1"];
	"Instantaneous Derivative Matching (IDM" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="1"];
	"Pearson‚Äôs correlation (PC" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="1"];
	"Directional Agreement (DA" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="1"];
	"speech quantity" [href="https://scholar.google.com/scholar?hl=en&q=Modelling%20and%20Identifying%20Collaborative%20Situations%20in%20a%20Collocated%20Multi-display%20Groupware%20Setting" target="_blank" , color="3"];
	"physical participation quantity" [href="https://scholar.google.com/scholar?hl=en&q=Modelling%20and%20Identifying%20Collaborative%20Situations%20in%20a%20Collocated%20Multi-display%20Groupware%20Setting" target="_blank" , color="4"];
	"number of active participants in group" [href="https://scholar.google.com/scholar?hl=en&q=Modelling%20and%20Identifying%20Collaborative%20Situations%20in%20a%20Collocated%20Multi-display%20Groupware%20Setting" target="_blank" , color="3"];
	"verbal participation symmetry among group" [href="https://scholar.google.com/scholar?hl=en&q=Modelling%20and%20Identifying%20Collaborative%20Situations%20in%20a%20Collocated%20Multi-display%20Groupware%20Setting" target="_blank" , color="3"];
	"gesture type and location" [href="https://scholar.google.com/scholar?hl=en&q=Improving%20Visibility%20of%20Remote%20Gestures%20in%20Distributed%20Tabletop%20Collaboration" target="_blank" , color="2"];
	"Joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Eye-Tracking%20Technology%20to%20Support%20Visual%20Coordination%20in%20Collaborative%20Problem-Solving%20Groups" target="_blank" , color="5"];
	"Joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="5"];
	"Convergence measures" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="4"];
	"Sequences of verbal utterances" [href="https://scholar.google.com/scholar?hl=en&q=Capturing%20and%20analyzing%20verbal%20and%20physical%20collaborative%20learning%20interactions%20at%20an%20enriched%20interactive%20tabletop" target="_blank" , color="3"];
	"Sequences of meaningful actions" [href="https://scholar.google.com/scholar?hl=en&q=Capturing%20and%20analyzing%20verbal%20and%20physical%20collaborative%20learning%20interactions%20at%20an%20enriched%20interactive%20tabletop" target="_blank" , color="4"];
	"physiological synchrony (DA" [href="https://scholar.google.com/scholar?hl=en&q=Unpacking%20the%20relationship%20between%20existing%20and%20new%20measures%20of%20physiological%20synchrony%20and%20collaborative%20learning:%20a%20mixed%20methods%20study" target="_blank" , color="1"];
	"cycles of physiological synchrony (PC" [href="https://scholar.google.com/scholar?hl=en&q=Unpacking%20the%20relationship%20between%20existing%20and%20new%20measures%20of%20physiological%20synchrony%20and%20collaborative%20learning:%20a%20mixed%20methods%20study" target="_blank" , color="1"];
	"Joint visual Attention" [href="https://scholar.google.com/scholar?hl=en&q=Leveraging%20Mobile%20Eye-Trackers%20to%20Capture%20Joint%20Visual%20Attention%20in%20Co-Located%20Collaborative%20Learning" target="_blank" , color="5"];
	"Cycles of collaborative / individual work" [href="https://scholar.google.com/scholar?hl=en&q=Leveraging%20Mobile%20Eye-Trackers%20to%20Capture%20Joint%20Visual%20Attention%20in%20Co-Located%20Collaborative%20Learning" target="_blank" , color="5"];
	"card movements" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="4"];
	"scrolling" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="4"];
	"zooming" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="4"];
	"1582 audio features (from Emobase" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="3"];
	"card movements" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="4"];
	"scrolling" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="4"];
	"zooming" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="4"];
	"1582 audio features (from Emobase" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="3"];
	"coherence" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="3"];
	"35 Coh-metrix indices" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20the%20Quality%20of%20Collaborative%20Problem%20Solving%20Through%20Linguistic%20Analysis%20of%20Discourse" target="_blank" , color="3"];
	"Physical synchrony" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20the%20Quality%20of%20Collaborative%20Problem%20Solving%20Through%20Linguistic%20Analysis%20of%20Discourse" target="_blank" , color="2"];
	"Total movement across upper body joints and body parts" [href="https://scholar.google.com/scholar?hl=en&q=Toward%20Using%20Multi-Modal%20Learning%20Analytics%20to%20Support%20and%20Measure%20Collaboration%20in%20Co-Located%20Dyads" target="_blank" , color="2"];
	"talking time" [href="https://scholar.google.com/scholar?hl=en&q=Toward%20Using%20Multi-Modal%20Learning%20Analytics%20to%20Support%20and%20Measure%20Collaboration%20in%20Co-Located%20Dyads" target="_blank" , color="3"];
	"Network features [+20]" [href="https://scholar.google.com/scholar?hl=en&q=Toward%20Collaboration%20Sensing" target="_blank" , color="5"];
	"Network features [+20]" [href="https://scholar.google.com/scholar?hl=en&q=Toward%20Collaboration%20Sensing" target="_blank" , color="5"];
	"joint-visual attention" [href="https://scholar.google.com/scholar?hl=en&q=Unpacking%20Collaborative%20Learning%20Processes%20during%20Hands-on%20Activities%20using%20Mobile%20Eye-Trackers" target="_blank" , color="5"];
	"joint-visual attention" [href="https://scholar.google.com/scholar?hl=en&q=Unpacking%20Collaborative%20Learning%20Processes%20during%20Hands-on%20Activities%20using%20Mobile%20Eye-Trackers" target="_blank" , color="5"];
	"joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=3D%20Tangibles%20Facilitate%20Joint%20Visual%20Attention%20in%20Dyads" target="_blank" , color="5"];
	"Joint movement" [href="https://scholar.google.com/scholar?hl=en&q=Exploring%20Collaboration%20Using%20Motion%20Sensors%20and%20Multi-Modal%20Learning%20Analytics" target="_blank" , color="2"];
	"dyad proximity" [href="https://scholar.google.com/scholar?hl=en&q=Exploring%20Collaboration%20Using%20Motion%20Sensors%20and%20Multi-Modal%20Learning%20Analytics" target="_blank" , color="2"];
	"speech time and frequency" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="3"];
	"symmetry of speech among group" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="3"];
	"total number of touch actions" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="4"];
	"symmetry of touch actions among group" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="4"];
	"shared gaze" [href="https://scholar.google.com/scholar?hl=en&q=Effects%20of%20Shared%20Gaze%20on%20Audio-%20Versus%20Text-Based%20Remote%20Collaborations" target="_blank" , color="5"];
	"speech time" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="3"];
	"thousands of features prosodic speech" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="3"];
	"movement of objects including revisiting past actions" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="4"];
	"Facial expression" -> "communication" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"Signal Matching (SM" -> "communication" [label="corr", labeltooltip=1, style="dotted", penwidth=1];
	"Instantaneous Derivative Matching (IDM" -> "communication" [label="corr", labeltooltip=1, style="dotted", penwidth=1];
	"Pearson‚Äôs correlation (PC" -> "communication" [label="corr", labeltooltip=1, style="dotted", penwidth=1];
	"Directional Agreement (DA" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"speech quantity" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"physical participation quantity" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"number of active participants in group" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"verbal participation symmetry among group" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"gesture type and location" -> "communication" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"Joint visual attention" -> "communication" [label="glm", labeltooltip=2, style="dotted", penwidth=2];
	"Convergence measures" -> "communication" [label="glm", labeltooltip=1, style="dotted", penwidth=1];
	"Sequences of verbal utterances" -> "communication" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Sequences of meaningful actions" -> "communication" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"physiological synchrony (DA" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"cycles of physiological synchrony (PC" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Joint visual Attention" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Cycles of collaborative / individual work" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"card movements" -> "communication" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"scrolling" -> "communication" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"zooming" -> "communication" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"1582 audio features (from Emobase" -> "communication" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"coherence" -> "communication" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"35 Coh-metrix indices" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Physical synchrony" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Total movement across upper body joints and body parts" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"talking time" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Network features [+20]" -> "communication" [label="corr", labeltooltip=2, style="solid", penwidth=2];
	"joint-visual attention" -> "communication" [label="corr", labeltooltip=2, style="solid", penwidth=2];
	"joint visual attention" -> "communication" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Joint movement" -> "communication" [label="corr", labeltooltip=1, style="dotted", penwidth=1];
	"dyad proximity" -> "communication" [label="corr", labeltooltip=1, style="dotted", penwidth=1];
	"speech time and frequency" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"symmetry of speech among group" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"total number of touch actions" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"symmetry of touch actions among group" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"shared gaze" -> "communication" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"speech time" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"thousands of features prosodic speech" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"movement of objects including revisiting past actions" -> "communication" [label="ml", labeltooltip=1, style="solid", penwidth=1];

 overlap=false 
 splines = true; 


}