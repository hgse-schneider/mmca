digraph world {
        size="15,15";
        layout=neato
        graph [fontname = "helvetica"];
        node [fontname = "helvetica", colorscheme=set28];
        edge [fontname = "helvetica", colorscheme=set28];

	"group composition" [href="index.svg"];
	"Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="5"];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="5"];
	"Speaking Distribution Cues (Speaking Length Skew, Speaking Turns Skew, Successful Interruption Skew, Unsuccessful Interruptions Skew, Backchannels Skew" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="5"];
	"Individual Visual Focus of Attention" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="6"];
	"Group Looking Cues (Fraction of People Gaze, Fraction of Convergent Gaze, Fraction of Mutual Gaze, Fraction of Shared Gaze, Gaze Skew" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="6"];
	"Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="5"];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="5"];
	"Calculator Use" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="1"];
	"Total Movement" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Distance from the center of the table" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Number of interventions" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="5"];
	"Total speech duration" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="5"];
	"Times numbers were mentioned" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="5"];
	"Times mathematical terms were mentioned" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="5"];
	"Times commands were pronounced" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="5"];
	"Total number of pen strokes" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="1"];
	"Average number of points" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="1"];
	"Average stroke time length" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="1"];
	"Average stroke path length" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="1"];
	"Average stroke displacement" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="1"];
	"Average stroke pressure" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="1"];
	"Speaking status" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="5"];
	"Pitch" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="5"];
	"Energy" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="5"];
	"Head motion" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="4"];
	"Body motion" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="3"];
	"Motion energy images" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="3"];
	"Gaze" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="6"];
	"Total manual gestures per second" [href="https://scholar.google.com/scholar?hl=en&q=Dynamic%20Adaptive%20Gesturing%20Predicts%20Domain%20Expertise%20in%20Mathematics" target="_blank" , color="3"];
	"Iconic gestures per second" [href="https://scholar.google.com/scholar?hl=en&q=Dynamic%20Adaptive%20Gesturing%20Predicts%20Domain%20Expertise%20in%20Mathematics" target="_blank" , color="3"];
	"Deictic gestures per second" [href="https://scholar.google.com/scholar?hl=en&q=Dynamic%20Adaptive%20Gesturing%20Predicts%20Domain%20Expertise%20in%20Mathematics" target="_blank" , color="3"];
	"duration of all vocalisations" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="5"];
	"average duration of vocalisation" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="5"];
	"standard deviation of vocalisation" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="5"];
	"probability of a transition from floor (i.e. a pause, group switching pause or speaker switching pause" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , ];
	"probability of a transition from a vocalisation to floor" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="5"];
	"probability of transitioning from a group vocalisation to speaker vocalisation" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="5"];
	"probability of transitioning from a speaker vocalisation to a group vocalisation" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="5"];
	"uncertainty in the transitions (turn taking" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="5"];
	"type of movement" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="3"];
	"Gaze location" [href="https://scholar.google.com/scholar?hl=en&q=Gaze%20quality%20assisted%20automatic%20recognition%20of%20social%20contexts%20in%20collaborative%20Tetris" target="_blank" , color="6"];
	"Gaze saccade" [href="https://scholar.google.com/scholar?hl=en&q=Gaze%20quality%20assisted%20automatic%20recognition%20of%20social%20contexts%20in%20collaborative%20Tetris" target="_blank" , color="6"];
	"Gaze fixation" [href="https://scholar.google.com/scholar?hl=en&q=Gaze%20quality%20assisted%20automatic%20recognition%20of%20social%20contexts%20in%20collaborative%20Tetris" target="_blank" , color="6"];
	"Player actions" [href="https://scholar.google.com/scholar?hl=en&q=Gaze%20quality%20assisted%20automatic%20recognition%20of%20social%20contexts%20in%20collaborative%20Tetris" target="_blank" , color="1"];
	"zoid acceleration" [href="https://scholar.google.com/scholar?hl=en&q=Gaze%20quality%20assisted%20automatic%20recognition%20of%20social%20contexts%20in%20collaborative%20Tetris" target="_blank" , color="1"];
	"22 Intra-Personal Features" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20classification%20and%20behaviour%20interpretation:%20An%20approach%20based%20on%20feature%20categories" target="_blank" , color="4"];
	"9 Dyadic Features" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20classification%20and%20behaviour%20interpretation:%20An%20approach%20based%20on%20feature%20categories" target="_blank" , color="4"];
	"6 One Vs All Features" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20classification%20and%20behaviour%20interpretation:%20An%20approach%20based%20on%20feature%20categories" target="_blank" , color="5"];
	"audio energy features" [href="https://scholar.google.com/scholar?hl=en&q=Investigating%20Automatic%20Dominance%20Estimation%20in%20Groups%20From%20Visual%20Attention%20and%20Speaking%20Activity" target="_blank" , color="5"];
	"visual focus of attention features" [href="https://scholar.google.com/scholar?hl=en&q=Investigating%20Automatic%20Dominance%20Estimation%20in%20Groups%20From%20Visual%20Attention%20and%20Speaking%20Activity" target="_blank" , color="6"];
	"speech utterances" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Interlocutor-Modulated%20Attention%20BLSTM%20to%20Predict%20Personality%20Traits%20in%20Small%20Group%20Interaction" target="_blank" , color="5"];
	"Pause duration" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="5"];
	"Articulation rate" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="5"];
	"peak slope" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="5"];
	"spectral stationarity" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="5"];
	"peak slope" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="5"];
	"Articulation rate" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="5"];
	"Pause duration" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="5"];
	"spectral stationarity" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="5"];
	"head/body movement" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="3"];
	"(non" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="5"];
	"speaking turn duration / number" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="5"];
	"interruption" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="5"];
	"head/body movement" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="3"];
	"(non" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="5"];
	"speaking turn duration / number" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="5"];
	"interruption" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="5"];
	"visual field of attention on a person features" [href="https://scholar.google.com/scholar?hl=en&q=Detecting%20Emergent%20Leader%20in%20a%20Meeting%20Environment" target="_blank" , color="6"];
	"body synchronization" [href="https://scholar.google.com/scholar?hl=en&q=Body%20synchrony%20in%20triadic%20interaction" target="_blank" , color="3"];
	"body synchronization" [href="https://scholar.google.com/scholar?hl=en&q=Body%20synchrony%20in%20triadic%20interaction" target="_blank" , color="3"];
	"speaking time % per individual" [href="https://scholar.google.com/scholar?hl=en&q=Employing%20Social%20Gaze%20and%20Speaking%20Activity%20for%20Automatic%20Determination%20of%20the%20Extraversion%20Trait" target="_blank" , color="5"];
	"attention received per person" [href="https://scholar.google.com/scholar?hl=en&q=Employing%20Social%20Gaze%20and%20Speaking%20Activity%20for%20Automatic%20Determination%20of%20the%20Extraversion%20Trait" target="_blank" , color="6"];
	"attention given by person" [href="https://scholar.google.com/scholar?hl=en&q=Employing%20Social%20Gaze%20and%20Speaking%20Activity%20for%20Automatic%20Determination%20of%20the%20Extraversion%20Trait" target="_blank" , color="6"];
	"Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels" -> "group composition" [label="glm", labeltooltip=2, style="solid", penwidth=2];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" -> "group composition" [label="glm", labeltooltip=2, style="solid", penwidth=2];
	"Speaking Distribution Cues (Speaking Length Skew, Speaking Turns Skew, Successful Interruption Skew, Unsuccessful Interruptions Skew, Backchannels Skew" -> "group composition" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Individual Visual Focus of Attention" -> "group composition" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Group Looking Cues (Fraction of People Gaze, Fraction of Convergent Gaze, Fraction of Mutual Gaze, Fraction of Shared Gaze, Gaze Skew" -> "group composition" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Calculator Use" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Total Movement" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Distance from the center of the table" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Number of interventions" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Total speech duration" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Times numbers were mentioned" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Times mathematical terms were mentioned" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Times commands were pronounced" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Total number of pen strokes" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Average number of points" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Average stroke time length" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Average stroke path length" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Average stroke displacement" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Average stroke pressure" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Speaking status" -> "group composition" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Pitch" -> "group composition" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Energy" -> "group composition" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Head motion" -> "group composition" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Body motion" -> "group composition" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Motion energy images" -> "group composition" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Gaze" -> "group composition" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Total manual gestures per second" -> "group composition" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"Iconic gestures per second" -> "group composition" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"Deictic gestures per second" -> "group composition" [label="glm", labeltooltip=1, style="dotted", penwidth=1];
	"duration of all vocalisations" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"average duration of vocalisation" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"standard deviation of vocalisation" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"probability of a transition from floor (i.e. a pause, group switching pause or speaker switching pause" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"probability of a transition from a vocalisation to floor" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"probability of transitioning from a group vocalisation to speaker vocalisation" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"probability of transitioning from a speaker vocalisation to a group vocalisation" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"uncertainty in the transitions (turn taking" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"type of movement" -> "group composition" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"Gaze location" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Gaze saccade" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Gaze fixation" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Player actions" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"zoid acceleration" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"22 Intra-Personal Features" -> "group composition" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"9 Dyadic Features" -> "group composition" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"6 One Vs All Features" -> "group composition" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"audio energy features" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"visual focus of attention features" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"speech utterances" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Pause duration" -> "group composition" [label="glm", labeltooltip=2, style="dotted", penwidth=2];
	"Articulation rate" -> "group composition" [label="glm", labeltooltip=2, style="dotted", penwidth=2];
	"peak slope" -> "group composition" [label="glm", labeltooltip=2, style="solid", penwidth=2];
	"spectral stationarity" -> "group composition" [label="glm", labeltooltip=2, style="dotted", penwidth=2];
	"head/body movement" -> "group composition" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"(non" -> "group composition" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"speaking turn duration / number" -> "group composition" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"interruption" -> "group composition" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"visual field of attention on a person features" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"body synchronization" -> "group composition" [label="glm", labeltooltip=2, style="solid", penwidth=2];
	"speaking time % per individual" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"attention received per person" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"attention given by person" -> "group composition" [label="ml", labeltooltip=1, style="solid", penwidth=1];

 overlap=false 
 splines = true; 


}