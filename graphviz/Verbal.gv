digraph world {
        size="15,15";
        layout=neato
        graph [fontname = "helvetica"];
        node [fontname = "helvetica", colorscheme=set28];
        edge [fontname = "helvetica", colorscheme=set28];

	"Verbal" [href="index.svg"];
	"verbal dominance and information metrics [9 metrics]" [href="https://scholar.google.com/scholar?hl=en&q=A%20Multimodal-Sensor-Enabled%20Room%20for%20Unobtrusive%20Group%20Meeting%20Analysis" target="_blank" , color="3"];
	"verbal dominance and information metrics [9 metrics]" [href="https://scholar.google.com/scholar?hl=en&q=A%20Multimodal-Sensor-Enabled%20Room%20for%20Unobtrusive%20Group%20Meeting%20Analysis" target="_blank" , color="3"];
	"non-verbal speaking metrics (speaking length, interruptions, etc" [href="https://scholar.google.com/scholar?hl=en&q=A%20Multimodal-Sensor-Enabled%20Room%20for%20Unobtrusive%20Group%20Meeting%20Analysis" target="_blank" , color="3"];
	"non-verbal speaking metrics (speaking length, interruptions, etc" [href="https://scholar.google.com/scholar?hl=en&q=A%20Multimodal-Sensor-Enabled%20Room%20for%20Unobtrusive%20Group%20Meeting%20Analysis" target="_blank" , color="3"];
	"non-verbal speaking metrics (speaking length, interruptions, etc" [href="https://scholar.google.com/scholar?hl=en&q=A%20Multimodal-Sensor-Enabled%20Room%20for%20Unobtrusive%20Group%20Meeting%20Analysis" target="_blank" , color="3"];
	"verbal dominance and information metrics [9 metrics]" [href="https://scholar.google.com/scholar?hl=en&q=A%20Multimodal-Sensor-Enabled%20Room%20for%20Unobtrusive%20Group%20Meeting%20Analysis" target="_blank" , color="3"];
	"non-verbal speaking metrics (speaking length, interruptions, etc" [href="https://scholar.google.com/scholar?hl=en&q=A%20Multimodal-Sensor-Enabled%20Room%20for%20Unobtrusive%20Group%20Meeting%20Analysis" target="_blank" , color="3"];
	"verbal dominance and information metrics [9 metrics]" [href="https://scholar.google.com/scholar?hl=en&q=A%20Multimodal-Sensor-Enabled%20Room%20for%20Unobtrusive%20Group%20Meeting%20Analysis" target="_blank" , color="3"];
	"Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Speaking Distribution Cues (Speaking Length Skew, Speaking Turns Skew, Successful Interruption Skew, Unsuccessful Interruptions Skew, Backchannels Skew" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Speaking Distribution Cues (Speaking Length Skew, Speaking Turns Skew, Successful Interruption Skew, Unsuccessful Interruptions Skew, Backchannels Skew" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Speaking Distribution Cues (Speaking Length Skew, Speaking Turns Skew, Successful Interruption Skew, Unsuccessful Interruptions Skew, Backchannels Skew" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Speaking Distribution Cues (Speaking Length Skew, Speaking Turns Skew, Successful Interruption Skew, Unsuccessful Interruptions Skew, Backchannels Skew" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" [href="https://scholar.google.com/scholar?hl=en&q=Linking%20Speaking%20and%20Looking%20Behavior%20Patterns%20with%20Group%20Composition,%20Perception,%20and%20Performance" target="_blank" , color="3"];
	"88 GeMAPS acoustic features" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"102 extended GeMAPs acoustic features" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"12 MFCCs" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"88 GeMAPS acoustic features" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"12 MFCCs" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"12 MFCCs" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"88 GeMAPS acoustic features" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"102 extended GeMAPs acoustic features" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"12 MFCCs" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20Recognition%20of%20Affective%20Laughter%20in%20Spontaneous%20Dyadic%20Interactions%20from%20Audiovisual%20Signals" target="_blank" , color="3"];
	"speech features" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20Group%20Performance%20in%20Task-Based%20Interaction" target="_blank" , color="3"];
	"linguistic features" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20Group%20Performance%20in%20Task-Based%20Interaction" target="_blank" , color="3"];
	"speech features" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20Group%20Performance%20in%20Task-Based%20Interaction" target="_blank" , color="3"];
	"linguistic features" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20Group%20Performance%20in%20Task-Based%20Interaction" target="_blank" , color="3"];
	"dialogue acts" [href="https://scholar.google.com/scholar?hl=en&q=The%20Additive%20Value%20of%20Multimodal%20Features%20for%20Predicting%20Engagement,%20Frustration,%20and%20Learning%20during%20Tutoring" target="_blank" , color="3"];
	"dialogue acts" [href="https://scholar.google.com/scholar?hl=en&q=The%20Additive%20Value%20of%20Multimodal%20Features%20for%20Predicting%20Engagement,%20Frustration,%20and%20Learning%20during%20Tutoring" target="_blank" , color="3"];
	"dialogue acts" [href="https://scholar.google.com/scholar?hl=en&q=The%20Additive%20Value%20of%20Multimodal%20Features%20for%20Predicting%20Engagement,%20Frustration,%20and%20Learning%20during%20Tutoring" target="_blank" , color="3"];
	"Dialogue episodes (description, management" [href="https://scholar.google.com/scholar?hl=en&q=Dual%20Gaze%20as%20a%20Proxy%20for%20Collaboration%20in%20Informal%20Learning" target="_blank" , color="3"];
	"Number of interventions" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Total speech duration" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Times numbers were mentioned" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Times mathematical terms were mentioned" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Times commands were pronounced" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Number of interventions" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Total speech duration" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Times numbers were mentioned" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Times mathematical terms were mentioned" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Times commands were pronounced" [href="https://scholar.google.com/scholar?hl=en&q=Expertise%20estimation%20based%20on%20simple%20multimodal%20features" target="_blank" , color="3"];
	"Speaking status" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="3"];
	"Pitch" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="3"];
	"Energy" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20Trait%20Classification%20via%20Co-Occurrent%20Multiparty%20Multimodal%20Event%20Discovery" target="_blank" , color="3"];
	"Sequences of verbal utterances" [href="https://scholar.google.com/scholar?hl=en&q=Capturing%20and%20analyzing%20verbal%20and%20physical%20collaborative%20learning%20interactions%20at%20an%20enriched%20interactive%20tabletop" target="_blank" , color="3"];
	"duration of all vocalisations" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="3"];
	"average duration of vocalisation" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="3"];
	"standard deviation of vocalisation" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="3"];
	"probability of a transition from floor (i.e. a pause, group switching pause or speaker switching pause" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , ];
	"probability of a transition from a vocalisation to floor" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="3"];
	"probability of transitioning from a group vocalisation to speaker vocalisation" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="3"];
	"probability of transitioning from a speaker vocalisation to a group vocalisation" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="3"];
	"uncertainty in the transitions (turn taking" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="3"];
	"transition probability between types of vocalisations" [href="https://scholar.google.com/scholar?hl=en&q=Automatic%20identification%20of%20experts%20and%20performance%20prediction%20in%20the%20multimodal%20math%20data%20corpus%20through%20analysis%20of%20speech%20interaction." target="_blank" , color="3"];
	"speech rate" [href="https://scholar.google.com/scholar?hl=en&q=Modeling%20Team-level%20Multimodal%20Dynamics%20during%20Multiparty%20Collaboration" target="_blank" , color="3"];
	"speech rate" [href="https://scholar.google.com/scholar?hl=en&q=Modeling%20Team-level%20Multimodal%20Dynamics%20during%20Multiparty%20Collaboration" target="_blank" , color="3"];
	"speech rate" [href="https://scholar.google.com/scholar?hl=en&q=Modeling%20Team-level%20Multimodal%20Dynamics%20during%20Multiparty%20Collaboration" target="_blank" , color="3"];
	"speech rate" [href="https://scholar.google.com/scholar?hl=en&q=Modeling%20Team-level%20Multimodal%20Dynamics%20during%20Multiparty%20Collaboration" target="_blank" , color="3"];
	"Proximity" [href="https://scholar.google.com/scholar?hl=en&q=Acoustic-Prosodic%20Entrainment%20and%20Rapport%20in%20Collaborative%20Learning%20Dialogues" target="_blank" , color="3"];
	"Convergence" [href="https://scholar.google.com/scholar?hl=en&q=Acoustic-Prosodic%20Entrainment%20and%20Rapport%20in%20Collaborative%20Learning%20Dialogues" target="_blank" , color="3"];
	"Synchrony" [href="https://scholar.google.com/scholar?hl=en&q=Acoustic-Prosodic%20Entrainment%20and%20Rapport%20in%20Collaborative%20Learning%20Dialogues" target="_blank" , color="3"];
	"6 One Vs All Features" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20classification%20and%20behaviour%20interpretation:%20An%20approach%20based%20on%20feature%20categories" target="_blank" , color="3"];
	"6 One Vs All Features" [href="https://scholar.google.com/scholar?hl=en&q=Personality%20classification%20and%20behaviour%20interpretation:%20An%20approach%20based%20on%20feature%20categories" target="_blank" , color="3"];
	"audio energy features" [href="https://scholar.google.com/scholar?hl=en&q=Investigating%20Automatic%20Dominance%20Estimation%20in%20Groups%20From%20Visual%20Attention%20and%20Speaking%20Activity" target="_blank" , color="3"];
	"1582 audio features (from Emobase" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="3"];
	"1582 audio features (from Emobase" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="3"];
	"speech utterances" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Interlocutor-Modulated%20Attention%20BLSTM%20to%20Predict%20Personality%20Traits%20in%20Small%20Group%20Interaction" target="_blank" , color="3"];
	"convergence (of linguistic styles" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="3"];
	"coherence" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="3"];
	"coherence" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="3"];
	"simple linguistic features" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="3"];
	"Speaking Activity (Speaking length, Speaking turns, Speaking interruptions, Average speaking turn duration" [href="https://scholar.google.com/scholar?hl=en&q=Emergent%20leaders%20through%20looking%20and%20speaking:%20from%20audio-visual%20data%20to%20multimodal%20recognition" target="_blank" , color="3"];
	"Speaking Activity (Speaking length, Speaking turns, Speaking interruptions, Average speaking turn duration" [href="https://scholar.google.com/scholar?hl=en&q=Emergent%20leaders%20through%20looking%20and%20speaking:%20from%20audio-visual%20data%20to%20multimodal%20recognition" target="_blank" , color="3"];
	"35 Coh-metrix indices" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20the%20Quality%20of%20Collaborative%20Problem%20Solving%20Through%20Linguistic%20Analysis%20of%20Discourse" target="_blank" , color="3"];
	"35 Coh-metrix indices" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20the%20Quality%20of%20Collaborative%20Problem%20Solving%20Through%20Linguistic%20Analysis%20of%20Discourse" target="_blank" , color="3"];
	"35 Coh-metrix indices" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20the%20Quality%20of%20Collaborative%20Problem%20Solving%20Through%20Linguistic%20Analysis%20of%20Discourse" target="_blank" , color="3"];
	"talking time" [href="https://scholar.google.com/scholar?hl=en&q=Toward%20Using%20Multi-Modal%20Learning%20Analytics%20to%20Support%20and%20Measure%20Collaboration%20in%20Co-Located%20Dyads" target="_blank" , color="3"];
	"Speaking turn features [x4]" [href="https://scholar.google.com/scholar?hl=en&q=Task-independent%20Multimodal%20Prediction%20of%20Group%20Performance%20Based%20on%20Product%20Dimensions" target="_blank" , color="3"];
	"Acoustic features [x13]" [href="https://scholar.google.com/scholar?hl=en&q=Task-independent%20Multimodal%20Prediction%20of%20Group%20Performance%20Based%20on%20Product%20Dimensions" target="_blank" , color="3"];
	"Linguistic features [x300+]" [href="https://scholar.google.com/scholar?hl=en&q=Task-independent%20Multimodal%20Prediction%20of%20Group%20Performance%20Based%20on%20Product%20Dimensions" target="_blank" , color="3"];
	"Mean audio level" [href="https://scholar.google.com/scholar?hl=en&q=Supervised%20machine%20learning%20in%20multimodal%20learning%20analytics%20for%20estimating%20success%20in%20project-based%20learning" target="_blank" , color="3"];
	"Pause duration" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="3"];
	"Articulation rate" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="3"];
	"peak slope" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="3"];
	"spectral stationarity" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="3"];
	"peak slope" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="3"];
	"Articulation rate" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="3"];
	"Pause duration" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="3"];
	"spectral stationarity" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20prediction%20of%20expertise%20and%20leadership%20in%20learning%20groups" target="_blank" , color="3"];
	"Audio level (AUD" [href="https://scholar.google.com/scholar?hl=en&q=Estimation%20of%20success%20in%20collaborative%20learning%20based%20on%20multimodal%20learning%20analytics%20features" target="_blank" , color="3"];
	"linguistic features from transcript (65 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"voice features (4 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"linguistic features from transcript (65 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"voice features (4 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"linguistic features from transcript (65 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"voice features (4 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"linguistic features from transcript (65 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"voice features (4 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"linguistic features from transcript (65 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"voice features (4 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"linguistic features from transcript (65 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"voice features (4 features" [href="https://scholar.google.com/scholar?hl=en&q=Multimodal%20Analysis%20of%20Vocal%20Collaborative%20Search:A%20Public%20Corpus%20and%20Results" target="_blank" , color="3"];
	"Speech activity" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="3"];
	"(non" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="3"];
	"speaking turn duration / number" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="3"];
	"interruption" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="3"];
	"(non" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="3"];
	"speaking turn duration / number" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="3"];
	"interruption" [href="https://scholar.google.com/scholar?hl=en&q=Moving%20as%20a%20Leader:%20Detecting%20Emergent%20Leadership%20in%20Small%20Groups%20using%20Body%20Pose" target="_blank" , color="3"];
	"speech time and frequency" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="3"];
	"symmetry of speech among group" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="3"];
	"speech quantity" [href="https://scholar.google.com/scholar?hl=en&q=Modelling%20and%20Identifying%20Collaborative%20Situations%20in%20a%20Collocated%20Multi-display%20Groupware%20Setting" target="_blank" , color="3"];
	"number of active participants in group" [href="https://scholar.google.com/scholar?hl=en&q=Modelling%20and%20Identifying%20Collaborative%20Situations%20in%20a%20Collocated%20Multi-display%20Groupware%20Setting" target="_blank" , color="3"];
	"verbal participation symmetry among group" [href="https://scholar.google.com/scholar?hl=en&q=Modelling%20and%20Identifying%20Collaborative%20Situations%20in%20a%20Collocated%20Multi-display%20Groupware%20Setting" target="_blank" , color="3"];
	"speaking time / turns" [href="https://scholar.google.com/scholar?hl=en&q=Multi-modal%20Social%20Signal%20Analysis%20for%20Predicting%20Agreement%20in%20Conversation%20Settings" target="_blank" , color="3"];
	"speech time" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="3"];
	"thousands of features prosodic speech" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="3"];
	"speaking time % per individual" [href="https://scholar.google.com/scholar?hl=en&q=Employing%20Social%20Gaze%20and%20Speaking%20Activity%20for%20Automatic%20Determination%20of%20the%20Extraversion%20Trait" target="_blank" , color="3"];
	"duration of speech by each student" [href="https://scholar.google.com/scholar?hl=en&q=Privacy-Preserving%20Speech%20Analytics%20for%20Automatic%20Assessment%20of%20Student%20Collaboration" target="_blank" , color="3"];
	"duration in which each student was only speaker" [href="https://scholar.google.com/scholar?hl=en&q=Privacy-Preserving%20Speech%20Analytics%20for%20Automatic%20Assessment%20of%20Student%20Collaboration" target="_blank" , color="3"];
	"duration of overlapping speech from pairs of students" [href="https://scholar.google.com/scholar?hl=en&q=Privacy-Preserving%20Speech%20Analytics%20for%20Automatic%20Assessment%20of%20Student%20Collaboration" target="_blank" , color="3"];
	"duration of overlapping speech from all people" [href="https://scholar.google.com/scholar?hl=en&q=Privacy-Preserving%20Speech%20Analytics%20for%20Automatic%20Assessment%20of%20Student%20Collaboration" target="_blank" , color="3"];
	"duration of silence for all people" [href="https://scholar.google.com/scholar?hl=en&q=Privacy-Preserving%20Speech%20Analytics%20for%20Automatic%20Assessment%20of%20Student%20Collaboration" target="_blank" , color="3"];
	"prosodic and tone features [many]" [href="https://scholar.google.com/scholar?hl=en&q=Privacy-Preserving%20Speech%20Analytics%20for%20Automatic%20Assessment%20of%20Student%20Collaboration" target="_blank" , color="3"];
	"Sequences of verbal utterances" [href="https://scholar.google.com/scholar?hl=en&q=Capturing%20and%20analyzing%20verbal%20and%20physical%20collaborative%20learning%20interactions%20at%20an%20enriched%20interactive%20tabletop" target="_blank" , color="3"];
	"Sequences of verbal utterances" [href="https://scholar.google.com/scholar?hl=en&q=Capturing%20and%20analyzing%20verbal%20and%20physical%20collaborative%20learning%20interactions%20at%20an%20enriched%20interactive%20tabletop" target="_blank" , color="3"];
	"speech rate" [href="https://scholar.google.com/scholar?hl=en&q=Modeling%20Team-level%20Multimodal%20Dynamics%20during%20Multiparty%20Collaboration" target="_blank" , color="3"];
	"1582 audio features (from Emobase" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="3"];
	"1582 audio features (from Emobase" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="3"];
	"1582 audio features (from Emobase" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="3"];
	"1582 audio features (from Emobase" [href="https://scholar.google.com/scholar?hl=en&q=High%20Accuracy%20Detection%20of%20Collaboration%20From%20Log%20Data%20and%20Superficial%20Speech%20Features" target="_blank" , color="3"];
	"coherence" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="3"];
	"coherence" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="3"];
	"35 Coh-metrix indices" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20the%20Quality%20of%20Collaborative%20Problem%20Solving%20Through%20Linguistic%20Analysis%20of%20Discourse" target="_blank" , color="3"];
	"35 Coh-metrix indices" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20the%20Quality%20of%20Collaborative%20Problem%20Solving%20Through%20Linguistic%20Analysis%20of%20Discourse" target="_blank" , color="3"];
	"talking time" [href="https://scholar.google.com/scholar?hl=en&q=Toward%20Using%20Multi-Modal%20Learning%20Analytics%20to%20Support%20and%20Measure%20Collaboration%20in%20Co-Located%20Dyads" target="_blank" , color="3"];
	"talking time" [href="https://scholar.google.com/scholar?hl=en&q=Toward%20Using%20Multi-Modal%20Learning%20Analytics%20to%20Support%20and%20Measure%20Collaboration%20in%20Co-Located%20Dyads" target="_blank" , color="3"];
	"Audio level (AUD" [href="https://scholar.google.com/scholar?hl=en&q=Estimation%20of%20success%20in%20collaborative%20learning%20based%20on%20multimodal%20learning%20analytics%20features" target="_blank" , color="3"];
	"speech time and frequency" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="3"];
	"speech time and frequency" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="3"];
	"symmetry of speech among group" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="3"];
	"symmetry of speech among group" [href="https://scholar.google.com/scholar?hl=en&q=An%20Automatic%20Approach%20for%20Mining%20Patterns%20of%20Collaboration%20around%20an%20Interactive%20Tabletop" target="_blank" , color="3"];
	"speech time" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="3"];
	"speech time" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="3"];
	"thousands of features prosodic speech" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="3"];
	"thousands of features prosodic speech" [href="https://scholar.google.com/scholar?hl=en&q=Using%20the%20Tablet%20Gestures%20and%20Speech%20of%20Pairs%20of%20Students%20to%20Classify%20Their%20Collaboration" target="_blank" , color="3"];
	"verbal dominance and information metrics [9 metrics]" -> "Verbal" [label="glm", labeltooltip=4, style="dotted", penwidth=4];
	"non-verbal speaking metrics (speaking length, interruptions, etc" -> "Verbal" [label="glm", labeltooltip=4, style="dotted", penwidth=4];
	"Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels" -> "Verbal" [label="glm", labeltooltip=4, style="solid", penwidth=4];
	"Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech" -> "Verbal" [label="glm", labeltooltip=6, style="solid", penwidth=6];
	"Speaking Distribution Cues (Speaking Length Skew, Speaking Turns Skew, Successful Interruption Skew, Unsuccessful Interruptions Skew, Backchannels Skew" -> "Verbal" [label="glm", labeltooltip=4, style="solid", penwidth=4];
	"88 GeMAPS acoustic features" -> "Verbal" [label="ml", labeltooltip=3, style="solid", penwidth=3];
	"102 extended GeMAPs acoustic features" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"12 MFCCs" -> "Verbal" [label="ml", labeltooltip=4, style="solid", penwidth=4];
	"speech features" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"linguistic features" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"dialogue acts" -> "Verbal" [label="glm", labeltooltip=3, style="solid", penwidth=3];
	"Dialogue episodes (description, management" -> "Verbal" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"Number of interventions" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"Total speech duration" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"Times numbers were mentioned" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"Times mathematical terms were mentioned" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"Times commands were pronounced" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"Speaking status" -> "Verbal" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Pitch" -> "Verbal" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Energy" -> "Verbal" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Sequences of verbal utterances" -> "Verbal" [label="clust", labeltooltip=3, style="solid", penwidth=3];
	"duration of all vocalisations" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"average duration of vocalisation" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"standard deviation of vocalisation" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"probability of a transition from floor (i.e. a pause, group switching pause or speaker switching pause" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"probability of a transition from a vocalisation to floor" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"probability of transitioning from a group vocalisation to speaker vocalisation" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"probability of transitioning from a speaker vocalisation to a group vocalisation" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"uncertainty in the transitions (turn taking" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"transition probability between types of vocalisations" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"speech rate" -> "Verbal" [label="clust", labeltooltip=5, style="dotted", penwidth=5];
	"Proximity" -> "Verbal" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Convergence" -> "Verbal" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Synchrony" -> "Verbal" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"6 One Vs All Features" -> "Verbal" [label="glm", labeltooltip=2, style="solid", penwidth=2];
	"audio energy features" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"1582 audio features (from Emobase" -> "Verbal" [label="ml", labeltooltip=6, style="solid", penwidth=6];
	"speech utterances" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"convergence (of linguistic styles" -> "Verbal" [label="corr", labeltooltip=1, style="dotted", penwidth=1];
	"coherence" -> "Verbal" [label="glm", labeltooltip=4, style="solid", penwidth=4];
	"simple linguistic features" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Speaking Activity (Speaking length, Speaking turns, Speaking interruptions, Average speaking turn duration" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"35 Coh-metrix indices" -> "Verbal" [label="corr", labeltooltip=5, style="solid", penwidth=5];
	"talking time" -> "Verbal" [label="corr", labeltooltip=3, style="solid", penwidth=3];
	"Speaking turn features [x4]" -> "Verbal" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Acoustic features [x13]" -> "Verbal" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Linguistic features [x300+]" -> "Verbal" [label="clust", labeltooltip=1, style="solid", penwidth=1];
	"Mean audio level" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Pause duration" -> "Verbal" [label="glm", labeltooltip=2, style="dotted", penwidth=2];
	"Articulation rate" -> "Verbal" [label="glm", labeltooltip=2, style="dotted", penwidth=2];
	"peak slope" -> "Verbal" [label="glm", labeltooltip=2, style="solid", penwidth=2];
	"spectral stationarity" -> "Verbal" [label="glm", labeltooltip=2, style="dotted", penwidth=2];
	"Audio level (AUD" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"linguistic features from transcript (65 features" -> "Verbal" [label="corr", labeltooltip=6, style="dotted", penwidth=6];
	"voice features (4 features" -> "Verbal" [label="corr", labeltooltip=6, style="dotted", penwidth=6];
	"Speech activity" -> "Verbal" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"(non" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"speaking turn duration / number" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"interruption" -> "Verbal" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"speech time and frequency" -> "Verbal" [label="ml", labeltooltip=3, style="solid", penwidth=3];
	"symmetry of speech among group" -> "Verbal" [label="ml", labeltooltip=3, style="solid", penwidth=3];
	"speech quantity" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"number of active participants in group" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"verbal participation symmetry among group" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"speaking time / turns" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"speech time" -> "Verbal" [label="ml", labeltooltip=3, style="solid", penwidth=3];
	"thousands of features prosodic speech" -> "Verbal" [label="ml", labeltooltip=3, style="solid", penwidth=3];
	"speaking time % per individual" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"duration of speech by each student" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"duration in which each student was only speaker" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"duration of overlapping speech from pairs of students" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"duration of overlapping speech from all people" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"duration of silence for all people" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"prosodic and tone features [many]" -> "Verbal" [label="ml", labeltooltip=1, style="solid", penwidth=1];

 overlap=false 
 splines = true; 


}