digraph world {
        size="10,10";
        layout=neato
        graph [fontname = "helvetica"];
        node [fontname = "helvetica", colorscheme=set28];
        edge [fontname = "helvetica", colorscheme=set28];

	"learning" [href="index.svg"];
	"Physiological linkage" [href="https://scholar.google.com/scholar?hl=en&q=Physiological%20Linkage%20of%20Dyadic%20Gaming%20Experience" target="_blank" , color="2"];
	"perceptual with-me-ness (gaze" [href="https://scholar.google.com/scholar?hl=en&q=Looking%20AT%20versus%20Looking%20THROUGH:%20A%20Dual%20Eye-tracking%20Study%20in%20MOOC%20Context" target="_blank" , color="6"];
	"conceptual with-me-ness (gaze" [href="https://scholar.google.com/scholar?hl=en&q=Looking%20AT%20versus%20Looking%20THROUGH:%20A%20Dual%20Eye-tracking%20Study%20in%20MOOC%20Context" target="_blank" , color="6"];
	"gaze similarity" [href="https://scholar.google.com/scholar?hl=en&q=Looking%20AT%20versus%20Looking%20THROUGH:%20A%20Dual%20Eye-tracking%20Study%20in%20MOOC%20Context" target="_blank" , color="6"];
	"dialogue acts" [href="https://scholar.google.com/scholar?hl=en&q=The%20Additive%20Value%20of%20Multimodal%20Features%20for%20Predicting%20Engagement,%20Frustration,%20and%20Learning%20during%20Tutoring" target="_blank" , color="5"];
	"facial expression" [href="https://scholar.google.com/scholar?hl=en&q=The%20Additive%20Value%20of%20Multimodal%20Features%20for%20Predicting%20Engagement,%20Frustration,%20and%20Learning%20during%20Tutoring" target="_blank" , color="4"];
	"gesture" [href="https://scholar.google.com/scholar?hl=en&q=The%20Additive%20Value%20of%20Multimodal%20Features%20for%20Predicting%20Engagement,%20Frustration,%20and%20Learning%20during%20Tutoring" target="_blank" , color="1"];
	"clustered hand/wrist movement" [href="https://scholar.google.com/scholar?hl=en&q=(Dis)Engagement%20Maters:%20Identifying%20Efficacious%20Learning%20Practices%20with%20Multimodal%20Learning%20Analytics" target="_blank" , color="1"];
	"(not" [href="https://scholar.google.com/scholar?hl=en&q=Dual%20Gaze%20as%20a%20Proxy%20for%20Collaboration%20in%20Informal%20Learning" target="_blank" , color="6"];
	"(not" [href="https://scholar.google.com/scholar?hl=en&q=Dual%20Gaze%20as%20a%20Proxy%20for%20Collaboration%20in%20Informal%20Learning" target="_blank" , color="6"];
	"Dialogue episodes (description, management" [href="https://scholar.google.com/scholar?hl=en&q=Dual%20Gaze%20as%20a%20Proxy%20for%20Collaboration%20in%20Informal%20Learning" target="_blank" , color="5"];
	"Joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Eye-Tracking%20Technology%20to%20Support%20Visual%20Coordination%20in%20Collaborative%20Problem-Solving%20Groups" target="_blank" , color="6"];
	"Joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="6"];
	"Convergence measures" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="3"];
	"Joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="6"];
	"Coherence metrics" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="3"];
	"N-grams" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="3"];
	"Cosine similarity scores" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="3"];
	"Convergence measures" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="3"];
	"Coherence metrics" [href="https://scholar.google.com/scholar?hl=en&q=The%20Effect%20of%20Mutual%20Gaze%20Perception%20on%20Students’%20Verbal%20Coordination" target="_blank" , color="3"];
	"Joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=Detecting%20Collaborative%20Dynamics%20Using%20Mobile%20Eye-Trackers" target="_blank" , color="6"];
	"amount of exploration" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="3"];
	"types of exploration" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="3"];
	"amount of movement" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="1"];
	"type of movement" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="1"];
	"Body synchronization" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="1"];
	"Body distance" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="1"];
	"amount of exploration" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="3"];
	"types of exploration" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="3"];
	"amount of movement" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="1"];
	"type of movement" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="1"];
	"Body synchronization" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="1"];
	"Body distance" [href="https://scholar.google.com/scholar?hl=en&q=Unraveling%20Students'%20Interaction%20around%20a%20Tangible%20Interface%20Using%20Multimodal%20Learning%20Analytics." target="_blank" , color="1"];
	"physiological synchrony (PC" [href="https://scholar.google.com/scholar?hl=en&q=Unpacking%20the%20relationship%20between%20existing%20and%20new%20measures%20of%20physiological%20synchrony%20and%20collaborative%20learning:%20a%20mixed%20methods%20study" target="_blank" , color="2"];
	"cycles of physiological synchrony (PC" [href="https://scholar.google.com/scholar?hl=en&q=Unpacking%20the%20relationship%20between%20existing%20and%20new%20measures%20of%20physiological%20synchrony%20and%20collaborative%20learning:%20a%20mixed%20methods%20study" target="_blank" , color="2"];
	"Cycles of collaborative / individual work" [href="https://scholar.google.com/scholar?hl=en&q=Leveraging%20Mobile%20Eye-Trackers%20to%20Capture%20Joint%20Visual%20Attention%20in%20Co-Located%20Collaborative%20Learning" target="_blank" , color="6"];
	"Joint visual Attention" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Mobile%20Eye-Trackers%20to%20Unpack%20the%20Perceptual%20Benefits%20of%20a%20Tangible%20User%20Interface%20for%20Collaborative%20Learning" target="_blank" , color="6"];
	"convergence (of linguistic styles" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="5"];
	"coherence" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="5"];
	"simple linguistic features" [href="https://scholar.google.com/scholar?hl=en&q=Does%20Seeing%20One%20Another’s%20Gaze%20Affect%20Group%20Dialogue?" target="_blank" , color="5"];
	"35 Coh-metrix indices" [href="https://scholar.google.com/scholar?hl=en&q=Predicting%20the%20Quality%20of%20Collaborative%20Problem%20Solving%20Through%20Linguistic%20Analysis%20of%20Discourse" target="_blank" , color="5"];
	"EVT of spatial entropy" [href="https://scholar.google.com/scholar?hl=en&q=An%20Alternate%20Statistical%20Lens%20to%20Look%20at%20Collaboration%20Data:%20Extreme%20Value%20Theory" target="_blank" , color="6"];
	"joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=3D%20Tangibles%20Facilitate%20Joint%20Visual%20Attention%20in%20Dyads" target="_blank" , color="6"];
	"joint visual attention" [href="https://scholar.google.com/scholar?hl=en&q=Real-time%20mutual%20gaze%20perception" target="_blank" , color="6"];
	"cognitive load (from pupil size" [href="https://scholar.google.com/scholar?hl=en&q=Real-time%20mutual%20gaze%20perception" target="_blank" , color="6"];
	"Signal Matching (SM" [href="https://scholar.google.com/scholar?hl=en&q=Investigating%20collaborative%20learning%20success%20with%20physiological%20coupling%20indices%20based%20on%20electrodermal%20activity" target="_blank" , color="2"];
	"Instantaneous Derivative Matching (IDM" [href="https://scholar.google.com/scholar?hl=en&q=Investigating%20collaborative%20learning%20success%20with%20physiological%20coupling%20indices%20based%20on%20electrodermal%20activity" target="_blank" , color="2"];
	"Pearson‚Äôs correlation coefficient (PCC" [href="https://scholar.google.com/scholar?hl=en&q=Investigating%20collaborative%20learning%20success%20with%20physiological%20coupling%20indices%20based%20on%20electrodermal%20activity" target="_blank" , color="2"];
	"Fisher‚Äôs z-transform (FZT" [href="https://scholar.google.com/scholar?hl=en&q=Investigating%20collaborative%20learning%20success%20with%20physiological%20coupling%20indices%20based%20on%20electrodermal%20activity" target="_blank" , color="2"];
	"Directional Agreement (DA" [href="https://scholar.google.com/scholar?hl=en&q=Investigating%20collaborative%20learning%20success%20with%20physiological%20coupling%20indices%20based%20on%20electrodermal%20activity" target="_blank" , color="2"];
	"Signal Matching (SM" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="2"];
	"Instantaneous Derivative Matching (IDM" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="2"];
	"Directional Agreement (DA" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="2"];
	"Pearson‚Äôs correlation (PC" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="2"];
	"Speech activity" [href="https://scholar.google.com/scholar?hl=en&q=Using%20Physiological%20Synchrony%20as%20an%20Indicator%20of%20Collaboration%20Quality,%20Task%20Performance%20and%20Learning" target="_blank" , color="5"];
	"Physiological linkage" -> "learning" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"perceptual with-me-ness (gaze" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"conceptual with-me-ness (gaze" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"gaze similarity" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"dialogue acts" -> "learning" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"facial expression" -> "learning" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"gesture" -> "learning" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"clustered hand/wrist movement" -> "learning" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"(not" -> "learning" [label="glm", labeltooltip=2, style="solid", penwidth=2];
	"Dialogue episodes (description, management" -> "learning" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"Joint visual attention" -> "learning" [label="corr", labeltooltip=4, style="solid", penwidth=4];
	"Convergence measures" -> "learning" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"Coherence metrics" -> "learning" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"N-grams" -> "learning" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"Cosine similarity scores" -> "learning" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"amount of exploration" -> "learning" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"types of exploration" -> "learning" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"amount of movement" -> "learning" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"type of movement" -> "learning" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"Body synchronization" -> "learning" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"Body distance" -> "learning" [label="ml", labeltooltip=2, style="solid", penwidth=2];
	"physiological synchrony (PC" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"cycles of physiological synchrony (PC" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Cycles of collaborative / individual work" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Joint visual Attention" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"convergence (of linguistic styles" -> "learning" [label="corr", labeltooltip=1, style="dotted", penwidth=1];
	"coherence" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"simple linguistic features" -> "learning" [label="ml", labeltooltip=1, style="solid", penwidth=1];
	"35 Coh-metrix indices" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"EVT of spatial entropy" -> "learning" [label="glm", labeltooltip=1, style="solid", penwidth=1];
	"joint visual attention" -> "learning" [label="glm", labeltooltip=2, style="solid", penwidth=2];
	"cognitive load (from pupil size" -> "learning" [label="glm", labeltooltip=1, style="dotted", penwidth=1];
	"Signal Matching (SM" -> "learning" [label="corr", labeltooltip=2, style="dotted", penwidth=2];
	"Instantaneous Derivative Matching (IDM" -> "learning" [label="corr", labeltooltip=2, style="dotted", penwidth=2];
	"Pearson‚Äôs correlation coefficient (PCC" -> "learning" [label="glm", labeltooltip=1, style="dotted", penwidth=1];
	"Fisher‚Äôs z-transform (FZT" -> "learning" [label="glm", labeltooltip=1, style="dotted", penwidth=1];
	"Directional Agreement (DA" -> "learning" [label="corr", labeltooltip=2, style="dotted", penwidth=2];
	"Pearson‚Äôs correlation (PC" -> "learning" [label="corr", labeltooltip=1, style="solid", penwidth=1];
	"Speech activity" -> "learning" [label="glm", labeltooltip=1, style="solid", penwidth=1];

 overlap=false 
 splines = true; 


}